from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint
import numpy as np

# Load the data
train_data = np.load('train_data.npy')
train_labels = np.load('train_labels.npy')
val_data = np.load('val_data.npy')
val_labels = np.load('val_labels.npy')

# Create the data generator
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

# Initialize the model
model = Sequential()

# Add the convolutional layer
model.add(Conv2D(32, (3,3), input_shape=(64, 64, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Conv2D(32, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Conv2D(32, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

# Flatten the data for the fully connected layers
model.add(Flatten())

# Add a fully connected layer
model.add(Dense(units=64, activation='relu'))
model.add(Dropout(0.5))

# Add the output layer
model.add(Dense(units=10, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Create callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10)
checkpointer = ModelCheckpoint(filepath='best_model.h5', save_best_only=True)

# Fit the model to the training data
model.fit_generator(datagen.flow(train_data, train_labels, batch_size=32),
                    steps_per_epoch=len(train_data) / 32,
                    epochs=100,
                    validation_data=(val_data, val_labels),
                    callbacks=[early_stopping, checkpointer])
